{"nbformat_minor": 0, "cells": [{"execution_count": null, "cell_type": "code", "source": "haiRaw = sc.textFile(\"wasb:///hai/HealthcareAssociatedInfections.txt\",16)\\\n    .map(lambda line: [x for x in line.split(\"\\t\")])\\\n    .filter(lambda r: r[0] != 'ProviderID')\\\n    .map(lambda r: (int(r[0]), str(r[1]), str(r[4]), str(r[8]), str(r[9]), str(r[10]), str(r[11])))\nhaiRaw.take(1)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.sql.types import *\nhaiSchema = StructType([StructField('ProviderID', IntegerType(), False),\n                     StructField('HospitalName', StringType(), True),\n                     StructField('State', StringType(), True),\n                     StructField('MeasureName', StringType(), True),\n                     StructField('MeasureID', StringType(), True),\n                     StructField('ComparedToNationalScore', StringType(), True),\n                     StructField('MeasureValue', StringType(), True)])\nhaiDF = sqlContext.createDataFrame(haiRaw, haiSchema)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "haiDF.cache()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "haiDF.show(1)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "haiDF.registerTempTable('hainfections')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT State,\n    AVG(MeasureValue) AS AverageScoreMRSA\nFROM hainfections\nWHERE MeasureID = 'HAI_5_SIR'\nGROUP BY State\nORDER BY State", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT State,\n    SUM(MeasureValue) AS ObservedCasesMRSA\nFROM hainfections\nWHERE MeasureID = 'HAI_5_NUMERATOR'\nGROUP BY State\nORDER BY State", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "mrsa = sqlContext.sql(\"SELECT State, \\\n                           MeasureValue AS ObservedCasesMRSA \\\n                       FROM hainfections \\\n                       WHERE MeasureID = 'HAI_5_NUMERATOR'\")\nmrsa.select(\"*\").write.save(\"mrsa.parquet\", format=\"parquet\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "hiveHaiDF = sqlContext.createDataFrame(haiRaw, haiSchema)\nhiveHaiDF.saveAsTable('infections')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nshow tables", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"name": "python"}}}}